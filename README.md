# VERBA_TEST_TASK

# Анализ задачи: Сбор данных с сайта Quotes to Scrape

## Что было сделано
- Написан скрипт для сбора цитат, авторов и тегов с сайта [Quotes to Scrape](https://quotes.toscrape.com/).
- Данные были сохранены в формате JSON.

## Откуда были получены данные
- Данные взяты с публичного сайта https://quotes.toscrape.com/.

## Как осуществлялся сбор
1. Использован модуль `requests` для загрузки HTML-страниц.
2. HTML-код обрабатывался с помощью библиотеки `BeautifulSoup`.
3. Данные о цитатах, авторах и тегах извлекались с помощью CSS-селекторов.
4. Реализован механизм перехода по страницам до завершения сканирования.

## Почему был выбран этот метод
- `requests` — простой и эффективный инструмент для работы с HTTP-запросами.
- `BeautifulSoup` — удобен для парсинга HTML и извлечения данных через селекторы.
- Альтернативы:
  - **Selenium**: не использовался из-за избыточности для задачи, так как сайт не содержит динамического контента.
  - **Scrapy**: мощный, но избыточный для небольшого проекта.

## Файлы
- `main.py`: основной скрипт для сбора данных.
- `quotes.json`: результат в формате JSON.
- `README.md`: анализ задачи.
